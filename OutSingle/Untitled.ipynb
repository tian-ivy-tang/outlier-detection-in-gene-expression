{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db05f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers.py\n",
    "import os\n",
    "from io import StringIO\n",
    "import math\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import mpmath as mp\n",
    "import multiprocess\n",
    "import statsmodels.api as sm  # for p-value FDR adjustment\n",
    "\n",
    "COUNT_INT = np.uint64\n",
    "if COUNT_INT == np.uint32:\n",
    "    # HIGHEST_COUNT = np.uint32(2 ** 32 - 1)\n",
    "    HIGHEST_COUNT = np.uint32(2 ** 24 - 1)\n",
    "elif COUNT_INT == np.uint64:\n",
    "    # HIGHEST_COUNT = np.uint64(2 ** 64 - 1)\n",
    "    # HIGHEST_COUNT = np.uint64(2 ** 32 - 1)\n",
    "    HIGHEST_COUNT = np.uint64(2 ** 24 - 1)\n",
    "\n",
    "\n",
    "def tsv_to_df(file_name, dtype=COUNT_INT):\n",
    "    # read tsv dataset into data frame only\n",
    "    file = pd.read_csv(file_name, sep=' ', header=0, )\n",
    "    file = file.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # filter out genes 0 counts in all samples\n",
    "    file = file.loc[(file != 0).any(axis=1)]\n",
    "\n",
    "    return file\n",
    "\n",
    "def csv_to_df(file_name, dtype=np.uint64):\n",
    "    # read intermediate csv outputs into data frame\n",
    "    file = pd.read_csv(file_name, sep='\\t', header=0, index_col=0)  # CSV file is comma-delimited by default ???\n",
    "    file = file.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    return file\n",
    "\n",
    "\n",
    "def get_size_factors(df):\n",
    "    _data = df.values\n",
    "    N = _data.shape[1]\n",
    "    _rows = []\n",
    "    for _row in _data:\n",
    "        if np.all(_row != 0):\n",
    "            _rows.append(_row)\n",
    "    J = len(_rows)\n",
    "    data = np.array(_rows)\n",
    "    data.shape = (J, N)\n",
    "    counts_normalized = np.zeros(data.shape, dtype=np.float64)\n",
    "    for j in range(data.shape[0]):\n",
    "        _row = np.array(data[j, :])\n",
    "        # counts = np.array([max(1, count) for count in row])\n",
    "        counts = np.array([count for count in _row if count != 0])\n",
    "        # print(counts)\n",
    "\n",
    "        # Geometric mean for one gene (all samples)\n",
    "        if len(counts) > 0:\n",
    "            # denominator = math.exp(np.mean(np.log(counts)))\n",
    "            denominator = mp_gmean(counts)\n",
    "            # print(counts)\n",
    "            # denominator = reduce(operator.mul, counts, 1) ** (1 / len(counts))\n",
    "            # denominator = reduce(lambda x, y: x*y, counts)**(1.0/len(counts))\n",
    "            # print(denominator)\n",
    "        else:\n",
    "            denominator = 0\n",
    "\n",
    "        if denominator == 0:\n",
    "            counts_normalized[j] = np.zeros(data.shape[1], dtype=np.float64)\n",
    "        else:\n",
    "            counts_normalized[j] = mp_fdiv(_row, denominator)\n",
    "    # print(counts_normalized)\n",
    "    size_factors = np.zeros(data.shape[1], dtype=np.float64)\n",
    "    for i in range(data.shape[1]):\n",
    "        column = np.array([count for count in counts_normalized[:, i] if count != 0])\n",
    "        size_factors[i] = np.median(column)\n",
    "    return size_factors\n",
    "\n",
    "\n",
    "def save_df_to_csv(data_df, file_name):\n",
    "    # if not os.path.exists(file_name):\n",
    "    data_df.to_csv(file_name, sep='\\t')\n",
    "\n",
    "    #     with open(file_name, 'r') as f:\n",
    "    #         # Removing the initial separator, as it makes problems for pd.read_csv\n",
    "    #         text = f.read()[1:]\n",
    "\n",
    "    #     with open(file_name, 'w') as f:\n",
    "    #         f.write(text)\n",
    "    # else:\n",
    "    #     print('The file', file_name, 'already exists, not saving...')\n",
    "\n",
    "\n",
    "def csv_to_df(file_name, dtype=COUNT_INT):\n",
    "    # read tsv dataset into data frame\n",
    "    file = pd.read_table(file_name, sep=' ', header=0, )\n",
    "    file = file.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # filter out genes with 0 counts in all samples\n",
    "    file = file.loc[(file != 0).any(axis=1)]\n",
    "\n",
    "    return file\n",
    "\n",
    "# seperate FDR adjusted p value calculation & export\n",
    "def save_dfz_to_csv(dfz, filename):\n",
    "    save_df_to_csv(dfz, filename)\n",
    "\n",
    "    dfp = pd.DataFrame(convert_zscores_to_pvalues(dfz.values), index=dfz.index, columns=dfz.columns)\n",
    "    filename_pv = os.path.splitext(filename)[0] + '-pv' + os.path.splitext(filename)[1]\n",
    "    save_df_to_csv(dfp, filename_pv)\n",
    "\n",
    "    return dfp\n",
    "\n",
    "\n",
    "def save_padj_to_csv(dfp, filename):    \n",
    "    dfp_adj = pd.DataFrame(0.0, columns=dfp.columns, index=dfp.index, dtype=np.float64)\n",
    "\n",
    "    # Apply FDR adjustment to each column of p value matrix, method BY <- see notebook bottom R script testing\n",
    "    for n in range(dfp_adj.shape[1]):\n",
    "        pv = dfp.iloc[:,n].to_list()\n",
    "        pv_adj = sm.stats.multipletests(pv, alpha=0.05, method='fdr_by')[1]  # return adjusted p values\n",
    "        dfp_adj.iloc[:, n] = pv_adj.reshape(dfp_adj.shape[0],1)\n",
    "\n",
    "    # get aberrant genes per sample with FDR < 0.05\n",
    "    aberrant_counts = dfp_adj.apply(lambda x: (x < 0.05).sum())  # by default apply to axis=0 each column\n",
    "    df_aberrant_per_sample = pd.DataFrame(aberrant_counts[aberrant_counts > 0].dropna()).T  # filter for only samples with outliers\n",
    "    filename_aberrant_per_sample = os.path.splitext(filename)[0] + '-aberrant-per-sample' + os.path.splitext(filename)[1]\n",
    "    save_df_to_csv(df_aberrant_per_sample, filename_aberrant_per_sample)\n",
    "    \n",
    "    # get results if Geuvadis dataset\n",
    "    if os.path.splitext(filename)[0] != 'Geuvadis-svd-optht-zs':\n",
    "        # add geneID as id column, melt matrix to get results table, add aberrant TRUE/FALSE column\n",
    "        dfp_adj.insert(0, \"geneID\", dfp_adj.index)\n",
    "        gene_results = pd.melt(dfp_adj, id_vars='geneID', var_name='sampleID', value_name='padjust')\n",
    "        gene_results['aberrant'] = gene_results['padjust'].apply(lambda x: 'TRUE' if x < 0.05 else 'FALSE')\n",
    "\n",
    "        # sort by adjusted p values & export\n",
    "        gene_results = gene_results.sort_values('padjust')\n",
    "        \n",
    "        filename_genes = os.path.splitext(filename)[0] + '-gene-results' + os.path.splitext(filename)[1]\n",
    "        save_df_to_csv(gene_results, filename_genes)\n",
    "\n",
    "\n",
    "def convert_zscores_to_pvalues(zs__):\n",
    "    return 2 * scipy.stats.norm.cdf(-np.abs(zs__))\n",
    "\n",
    "\n",
    "def clean_zs(data):\n",
    "    _tmp = np.copy(data)\n",
    "    _tmp[np.isinf(_tmp)] = 0\n",
    "    _tmp[np.isneginf(_tmp)] = 0\n",
    "    data[np.isinf(data)] = max(7, np.abs(_tmp).max())\n",
    "    data[np.isneginf(data)] = min(-7, -np.abs(_tmp).max())\n",
    "    return data\n",
    "\n",
    "\n",
    "mp_power = np.frompyfunc(mp.power, 2, 1)\n",
    "mp_fdiv = np.frompyfunc(mp.fdiv, 2, 1)\n",
    "\n",
    "\n",
    "def mp_gmean(array):\n",
    "    return mp_power(mp_fprod((mp.mpf(str(e)) for e in array)), (1.0 / len(array)))\n",
    "\n",
    "\n",
    "def mp_fprod2(a, b):\n",
    "    return mp.fprod([a, b])\n",
    "\n",
    "\n",
    "def mp_fprod(list_):\n",
    "    f = np.frompyfunc(mp_fprod2, 2, 1)\n",
    "    res = mp.mpf('1')\n",
    "    for e in list_:\n",
    "        res = f(res, e)\n",
    "    return res\n",
    "\n",
    "\n",
    "def transform(a, transform_f, axis=None, print_=False, mp=True):\n",
    "    # a = a.astype(np.float64)\n",
    "    # a += 0.001\n",
    "    a_new = np.zeros_like(a, dtype=np.float64)\n",
    "    if len(a.shape) == 1 or axis is None:\n",
    "        shape = a.shape\n",
    "        a = np.ravel(a)\n",
    "        a_new = transform_f(a)\n",
    "        a_new.shape = shape\n",
    "        return a_new\n",
    "    elif axis == 0:  # Column-wise'\n",
    "        def f(c, column):\n",
    "            if print_:\n",
    "                print('Processing column', c)\n",
    "            return c, transform_f(column)\n",
    "        if mp:\n",
    "            # multiprocessing\n",
    "            # n_parts = math.floor(multiprocess.cpu_count() * 3 / 4) or 1\n",
    "            n_parts = math.floor(multiprocess.cpu_count() * 5 / 12) or 1\n",
    "            with multiprocess.Pool(processes=n_parts) as pool:\n",
    "                results = pool.starmap(f, zip(range(a.shape[1]), (a[:, c] for c in range(a.shape[1]))))\n",
    "            results.sort()\n",
    "            for c in range(a.shape[1]):\n",
    "                a_new[:, c] = results[c][1]\n",
    "        else:\n",
    "            # Single-processing\n",
    "            for c in range(a.shape[1]):\n",
    "                if print_:\n",
    "                    print('Processing column', c)\n",
    "                a_new[:, c] = transform_f(a[:, c])\n",
    "        return a_new\n",
    "    elif axis == 1:  # Row-wise\n",
    "        def f(r, row):\n",
    "            if print_:\n",
    "                print('Processing row', r)\n",
    "            return r, transform_f(row)\n",
    "        if mp:\n",
    "            # multiprocessing\n",
    "            # n_parts = math.floor(multiprocess.cpu_count() * 3 / 4) or 1\n",
    "            n_parts = math.floor(multiprocess.cpu_count() * 5 / 12) or 1\n",
    "            with multiprocess.Pool(processes=n_parts) as pool:\n",
    "                results = pool.starmap(f, zip(range(a.shape[0]), (a[r, :] for r in range(a.shape[0]))))\n",
    "            results.sort()\n",
    "            for r in range(a.shape[0]):\n",
    "                a_new[r, :] = results[r][1]\n",
    "        else:\n",
    "            # Single-processing\n",
    "            for r in range(a.shape[0]):\n",
    "                if print_:\n",
    "                    print('Processing row', r)\n",
    "                a_new[r, :] = transform_f(a[r, :])\n",
    "        return a_new\n",
    "    else:\n",
    "        raise Exception('Cannot happen')\n",
    "\n",
    "\n",
    "def _std(data):\n",
    "    assert len(data.shape) == 1\n",
    "    N = len(data)\n",
    "    data = clean_zs(data)\n",
    "    # mu = data.mean()\n",
    "    mu = np.median(data)\n",
    "    try:\n",
    "        c4 = np.sqrt(2/(N - 1)) * math.gamma(N/2) / math.gamma((N - 1)/2)\n",
    "    except OverflowError: # N too big\n",
    "        c4 = 1 - 1/4/N - 7/32/(N**2) - 19/128/(N**3)\n",
    "    # std = data.std(ddof=1) / c4\n",
    "    std = 1.4826 * mad(data) / c4\n",
    "    # std = np.sqrt(((data - mu) ** 2).sum() / (data.size - 1))\n",
    "    if std == 0:\n",
    "        std = 0.000000000000001\n",
    "\n",
    "    return std\n",
    "\n",
    "\n",
    "def std(data, axis=None):\n",
    "    return transform(data, _std, axis=axis, mp=False)\n",
    "\n",
    "\n",
    "def mad(arr):\n",
    "    \"\"\" Median Absolute Deviation: a \"Robust\" version of standard deviation.\n",
    "        Indices variabililty of the sample.\n",
    "        https://en.wikipedia.org/wiki/Median_absolute_deviation\n",
    "    \"\"\"\n",
    "    arr = np.ma.array(arr).compressed() # should be faster to not use masked arrays.\n",
    "    med = np.median(arr)\n",
    "    return np.median(np.abs(arr - med))\n",
    "\n",
    "\n",
    "def _standardize(data):\n",
    "    assert len(data.shape) == 1\n",
    "    N = len(data)\n",
    "    data = clean_zs(data)\n",
    "    mu = data.mean()\n",
    "    # mu = np.median(data)\n",
    "    try:\n",
    "        c4 = np.sqrt(2/(N - 1)) * math.gamma(N/2) / math.gamma((N - 1)/2)\n",
    "    except OverflowError: # N too big\n",
    "        c4 = 1 - 1/4/N - 7/32/(N**2) - 19/128/(N**3)\n",
    "    std = data.std(ddof=1) / c4\n",
    "    # std = 1.4826 * mad(data) / c4\n",
    "    # std = np.sqrt(((data - mu) ** 2).sum() / (data.size - 1))\n",
    "    if std == 0:\n",
    "        std = 0.000000000000001\n",
    "\n",
    "    return (data - mu) / std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
